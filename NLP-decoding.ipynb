{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /Users/Nada-Al-\n",
      "[nltk_data]     Thawr/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# You should not modify code in this cell\n",
    "import sys\n",
    "import nltk \n",
    "import numpy\n",
    "from nltk.corpus import treebank\n",
    "nltk.download('treebank')\n",
    "\n",
    "# Get number of sentences POS-tagged sentences from the treebank corpus\n",
    "def get_pos_data(numsents):\n",
    "\n",
    "    # Extract required number of sentences\n",
    "    sentences = treebank.tagged_sents()[:numsents]\n",
    "\n",
    "    # Initialize\n",
    "    sequences = []\n",
    "    symbols = set()\n",
    "    tag_set = set()\n",
    "    \n",
    "    # Go over each extracted sentence ...\n",
    "    for sentence in sentences:\n",
    "        for i in range(len(sentence)):\n",
    "            word, tag = sentence[i]\n",
    "            word = word.lower()  # normalize case\n",
    "            symbols.add(word)    # add this word\n",
    "            tag_set.add(tag)\n",
    "            sentence[i] = (word, tag)  # store tagged token\n",
    "        sequences.append(sentence)\n",
    "\n",
    "    # Return sequences, the list of tags and all the words that we saw\n",
    "    return sequences, list(tag_set), list(symbols)\n",
    "\n",
    "# Train the transition and emission probabilities\n",
    "def train():\n",
    "    print('Training HMM...')\n",
    "\n",
    "    # Use the first 5000 sentences from treebank corpus\n",
    "    labelled_sequences, states, symbols = get_pos_data(5000)\n",
    "    \n",
    "    # Define the estimator to be used for probability computation\n",
    "    estimator = lambda fd, bins: nltk.LidstoneProbDist(fd, 0.1, bins)\n",
    "    \n",
    "    # count occurences of starting states, transitions out of each state\n",
    "    # and output symbols observed in each state\n",
    "    freq_starts = nltk.FreqDist()\n",
    "    freq_transitions = nltk.ConditionalFreqDist()\n",
    "    freq_emissions = nltk.ConditionalFreqDist()\n",
    "    for sequence in labelled_sequences:\n",
    "        lasts = None\n",
    "        for token in sequence:\n",
    "            state = token[1]\n",
    "            symbol = token[0]\n",
    "            if lasts == None:\n",
    "                freq_starts[state] += 1\n",
    "            else:\n",
    "                freq_transitions[lasts][state] += 1\n",
    "            freq_emissions[state][symbol] += 1\n",
    "            lasts = state\n",
    "\n",
    "            # update the state and symbol lists\n",
    "            if state not in states:\n",
    "                states.append(state)\n",
    "            if symbol not in symbols:\n",
    "                symbols.append(symbol)\n",
    "\n",
    "    # create probability distributions (with smoothing)\n",
    "    N = len(states) \n",
    "    \n",
    "    starts = estimator(freq_starts, N)\n",
    "    transitions = nltk.ConditionalProbDist(freq_transitions, estimator, N)\n",
    "    emissions = nltk.ConditionalProbDist(freq_emissions, estimator, len(symbols))\n",
    "                               \n",
    "    print('Training Complete') \n",
    "    \n",
    "    # Return the transition and emissions probabilities along with \n",
    "    # the list of all the states and output symbols\n",
    "    return starts, transitions, emissions, states, symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training HMM...\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "from numpy import zeros, array, float32, int16, argmax\n",
    "from math import log, exp\n",
    "from nltk import re\n",
    "# call the train function (it will take some time)\n",
    "priors, transitions, emissions, states, symbols = train()\n",
    "# suggestion: inspect these five variables and the code in train() \n",
    "# to get a sense of the data and data structures\n",
    "\n",
    "\n",
    "# write your viterbi code here  \n",
    "#takes a string of words as an argument\n",
    "def viterbi(string_words): \n",
    "    #reg expression to remove all punctuations \n",
    "    sentence = re.compile(r\"[\\w']+|[(){}.,!?;]\")\n",
    "    observations = sentence.findall(string_words)\n",
    "    \n",
    "    N = len(states)\n",
    "    T = len(observations)\n",
    "    \n",
    "    backpointer = {}\n",
    "    matrix = numpy.zeros(shape=(N,T), dtype=float32) \n",
    "    \n",
    "    #fills the matrix and the backpointer\n",
    "    for x in range (0,N):\n",
    "        matrix[x][0] = priors.logprob(states[x]) + emissions[states[x]].logprob(observations[0])\n",
    "        backpointer[x,0] = 0  \n",
    "   \n",
    "    for y in range (1,T):\n",
    "        for x in range (0,N):           \n",
    "            prev_state = None\n",
    "            \n",
    "            for z in range (0, N): \n",
    "                current_probability = matrix[z][y-1]+transitions[states[z]].logprob(states[x]) \n",
    "                + emissions[states[x]].logprob(observations[y])\n",
    "                if not prev_state or current_probability > prev_state[0]:\n",
    "                    prev_state = (current_probability, states[z])\n",
    "            matrix[x][y] = prev_state[0]\n",
    "            backpointer[states[x], y] = prev_state[1]\n",
    "        \n",
    "    temp = None\n",
    "    for n in range(0,N):\n",
    "        current_val = matrix[n,T-1]\n",
    "        if not temp or current_val > temp[0]:\n",
    "            temp = (current_val, states[n])\n",
    "                \n",
    "    current = temp[1]\n",
    "    bestpath = [current]\n",
    "    for i in range(T-1, 0, -1):\n",
    "        last_val = backpointer[current,i]\n",
    "        bestpath.append(last_val)\n",
    "        current = last_val\n",
    "\n",
    "    bestpath.reverse()\n",
    "#     print(bestpath)\n",
    "    return observations, bestpath\n",
    "\n",
    "# sentence = 'hello world'\n",
    "# viterbi(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tagViterbi(f):\n",
    "    lines = f.readlines()\n",
    "    for i in lines:\n",
    "#         line = re.compile(r\"[\\w']+|[(){}.,!?;]\")\n",
    "        symbols, path = viterbi(i)\n",
    "#         print(\"sym\" + symbols)\n",
    "#         symbols = re.sub(r'[^\\w\\s]','',symbols)\n",
    "        for j in range(0, len(path)):\n",
    "#             symbols[j] = re.sub(r'[^\\w\\s]','',symbols[j])\n",
    "#             if(symbols[j] != '.'):\n",
    "            print(symbols[j] + '/' + str(path[j]) + \" \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i/PRP \n",
      "wonder/MD \n",
      "how/VB \n",
      "many/DT \n",
      "miles/NNP \n",
      "i/NNP \n",
      "'ve/NNP \n",
      "fallen/NNP \n",
      "by/NNP \n",
      "this/NNP \n",
      "time/NNP \n",
      "./NNP \n",
      "i/PRP \n",
      "would/MD \n",
      "not/VB \n",
      "like/DT \n",
      "green/NN \n",
      "eggs/IN \n",
      "and/DT \n",
      "ham/NN \n",
      "./IN \n",
      "emma/NNP \n",
      "spared/NNP \n",
      "no/NNP \n",
      "exertions/NNP \n",
      "to/NNP \n",
      "maintain/NNP \n",
      "this/NNP \n",
      "happier/NNP \n",
      "flow/NNP \n",
      "of/NNP \n",
      "ideas/NNP \n",
      "./NNP \n",
      "while/IN \n",
      "these/NNP \n",
      "things/NNP \n",
      "go/NNP \n",
      "up/NNP \n",
      "other/NNP \n",
      "things/NNP \n",
      "come/NNP \n",
      "down/NNP \n",
      "./NNP \n",
      "if/IN \n",
      "it/NNP \n",
      "were/NNP \n",
      "a/NNP \n",
      "hollywood/NNP \n",
      "movie/NNP \n",
      ",/NNP \n",
      "you/NNP \n",
      "'d/NNP \n",
      "never/NNP \n",
      "believe/NNP \n",
      "it/NNP \n",
      "./NNP \n"
     ]
    }
   ],
   "source": [
    "# open test-sentences\n",
    "testSentenceFile = open('test-sentences.txt')\n",
    "tagViterbi(testSentenceFile) # you need to define a tagViterbi function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the/DT \n",
      "report/NN \n",
      "is/IN \n",
      "subject/DT \n",
      "to/NN \n",
      "review/. \n",
      "./'' \n",
      "the/DT \n",
      "balance/NN \n",
      "is/IN \n",
      "n't/DT \n",
      "being/NN \n",
      "budgeted/IN \n",
      "for/DT \n",
      "the/NN \n",
      "coming/IN \n",
      "year/DT \n",
      "./NN \n",
      "we/PRP \n",
      "begin/MD \n",
      "by/VB \n",
      "considering/DT \n",
      "the/NNP \n",
      "much/NNP \n",
      "simpler/NNP \n",
      "case/NNP \n",
      "of/NNP \n",
      "the/NNP \n",
      "markov/NNP \n",
      "chain/NNP \n",
      "./NNP \n",
      "somewhere/NNP \n",
      ",/NNP \n",
      "somebody/NNP \n",
      "is/NNP \n",
      "bound/NNP \n",
      "to/NNP \n",
      "love/NNP \n",
      "us/NNP \n",
      "./NNP \n",
      "none/NNP \n",
      "of/NNP \n",
      "the/NNP \n",
      "trujillo/NNP \n",
      "family/NNP \n",
      "remains/NNP \n",
      "./NNP \n"
     ]
    }
   ],
   "source": [
    "# eventually, open the hw-sentences\n",
    "hwSentenceFile = open('hw-sentences.txt')\n",
    "tagViterbi(hwSentenceFile) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
